import streamlit as st
from PIL import Image
import base64
import io

import torch
from llava.model.builder import load_pretrained_model
from llava.conversation import conv_templates, SeparatorStyle
from llava.utils import disable_torch_init
from llava.mm_utils import get_model_name_from_path, process_images, tokenizer_image_token, KeywordsStoppingCriteria
from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN
from transformers import TextStreamer
import re


# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="KOMPSAT Image Chatbot",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ëª¨ë¸ ì„¤ì •
@st.cache_resource
def load_model():
    """ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë”©í•˜ëŠ” í•¨ìˆ˜"""
    args = {
        "model_path": "./checkpoints/llava-Qwen2.5-7B-Instruct-s2-finetune-kompsat",
        "conv_mode": "qwen_2_5",
        "temperature": 0.6,
        "max_new_tokens": 1024,
    }
    
    model_name = get_model_name_from_path(args["model_path"])
    
    disable_torch_init()
    tokenizer, model, image_processor, _ = load_pretrained_model(
        args["model_path"],
        model_base=None,
        model_name=model_name
    )
    
    return tokenizer, model, image_processor, args

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None

if "conv" not in st.session_state:
    st.session_state.conv = None

def encode_image_to_base64(image):
    """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return img_str

def display_chat_message(role, content):
    """ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ"""
    with st.chat_message(role):
        st.write(content)

def clean_output(text):
    """ì¶œë ¥ì—ì„œ íŠ¹ìˆ˜ í† í° ì œê±°"""
    # <|im_end|>, <|im_start|> ë“±ì˜ íŠ¹ìˆ˜ í† í° ì œê±°
    text = re.sub(r'<\|im_end\|>', '', text)
    text = re.sub(r'<\|im_start\|>', '', text)
    text = re.sub(r'<\|.*?\|>', '', text)  # ê¸°íƒ€ íŠ¹ìˆ˜ í† í°ë“¤
    return text.strip()

class StreamlitStreamer:
    """Streamlitìš© ì»¤ìŠ¤í…€ ìŠ¤íŠ¸ë¦¬ë¨¸"""
    def __init__(self, tokenizer, placeholder):
        self.tokenizer = tokenizer
        self.placeholder = placeholder
        self.text = ""
        self.buffer = ""
        
    def put(self, value):
        if len(value.shape) > 1:
            value = value[0]
        
        # í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë””ì½”ë“œ
        token_text = self.tokenizer.decode(value, skip_special_tokens=True)
        
        # íŠ¹ìˆ˜ í† í°ì´ í¬í•¨ëœ ê²½ìš° ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨
        if '<|im_end|>' in token_text:
            return
            
        self.text += token_text
        
        # ë²„í¼ì— ì¶”ê°€
        self.buffer += token_text
        
        # ì™„ì „í•œ ë¬¸ì ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        try:
            # í˜„ì¬ê¹Œì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ë””ì½”ë”©
            decoded_text = self.text.encode('utf-8').decode('utf-8')
            # íŠ¹ìˆ˜ í† í° ì œê±°
            clean_text = clean_output(decoded_text)
            # í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ ì œê±°
            if "<|im_start|>assistant\n" in clean_text:
                clean_text = clean_text.split("<|im_start|>assistant\n")[-1]
            # í™”ë©´ì— í‘œì‹œ
            self.placeholder.write(clean_text)
        except UnicodeDecodeError:
            # ë””ì½”ë”©ì´ ì‹¤íŒ¨í•˜ë©´ ë²„í¼ë§ë§Œ í•˜ê³  í‘œì‹œí•˜ì§€ ì•ŠìŒ
            pass
        
    def end(self):
        # ë§ˆì§€ë§‰ì— ë²„í¼ì˜ ë‚´ìš©ì„ í•œ ë²ˆì— í‘œì‹œ
        try:
            decoded_text = self.text.encode('utf-8').decode('utf-8')
            clean_text = clean_output(decoded_text)
            if "<|im_start|>assistant\n" in clean_text:
                clean_text = clean_text.split("<|im_start|>assistant\n")[-1]
            self.placeholder.write(clean_text)
        except UnicodeDecodeError:
            # ë””ì½”ë”© ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ í‘œì‹œ
            self.placeholder.write(self.text)

def main():
    # ëª¨ë¸ ë¡œë”© (ìºì‹œë¨)
    tokenizer, model, image_processor, args = load_model()
    
    # conversation ì´ˆê¸°í™”
    if st.session_state.conv is None:
        st.session_state.conv = conv_templates[args["conv_mode"]].copy()

    st.title("ğŸ¤– LLaVA-Lucid-mini Chatbot")
    st.markdown("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸í•´ë³´ì„¸ìš”!")
    
    # ì‚¬ì´ë“œë°” - ì´ë¯¸ì§€ ì—…ë¡œë“œ
    with st.sidebar:
        # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ì„ ìƒë‹¨ì— ì¶”ê°€
        if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", key="reset_chat", use_container_width=True):
            st.session_state.messages = []
            st.session_state.uploaded_image = None
            if "image_first_use" in st.session_state:
                del st.session_state.image_first_use
            st.session_state.conv = conv_templates[args["conv_mode"]].copy()
            st.rerun()
        
        st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€
        
        st.header("ğŸ“· ì´ë¯¸ì§€ ì—…ë¡œë“œ")
        
        uploaded_file = st.file_uploader(
            "ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”",
            type=['png', 'jpg', 'jpeg', 'gif', 'bmp'],
            help="PNG, JPG, JPEG, GIF, BMP í˜•ì‹ì„ ì§€ì›í•©ë‹ˆë‹¤"
        )
        
        if uploaded_file is not None:
            # ì´ë¯¸ì§€ ë¡œë“œ ë° í‘œì‹œ
            image = Image.open(uploaded_file)
            st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", width=250, use_container_width=True)
            st.session_state.uploaded_image = image
            
            if "image_first_use" not in st.session_state:
                st.session_state.image_first_use = True
            
                
                
            # ì´ë¯¸ì§€ ì •ë³´ í‘œì‹œ
            st.write(f"**íŒŒì¼ëª…:** {uploaded_file.name}")
            st.write(f"**í¬ê¸°:** {image.size}")
            st.write(f"**í¬ë§·:** {image.format}")
        
        # ì´ë¯¸ì§€ê°€ ì œê±°ë˜ì—ˆì„ ë•Œ ì²˜ë¦¬
        if uploaded_file is None and st.session_state.uploaded_image is not None:
            # ì´ë¯¸ì§€ê°€ ì œê±°ë˜ë©´ ê´€ë ¨ ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.uploaded_image = None
            if "image_first_use" in st.session_state:
                del st.session_state.image_first_use
            st.rerun()
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    chat_container = st.container()
    
    with chat_container:
        # ì´ì „ ë©”ì‹œì§€ë“¤ í‘œì‹œ
        for message in st.session_state.messages:
            display_chat_message(
                message["role"], 
                message["content"], 
            )
    
    # ì±„íŒ… ì…ë ¥
    if input_text := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        user_message = {
            "role": "user",
            "content": input_text,
            "image": st.session_state.uploaded_image
        }
        st.session_state.messages.append(user_message)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        display_chat_message("user", input_text)
        
        # AI ì‘ë‹µ ìƒì„± 
        conv = st.session_state.conv
        
        if st.session_state.image_first_use:
            # first message
            if model.config.mm_use_im_start_end:
                input_text = DEFAULT_IM_START_TOKEN + DEFAULT_IMAGE_TOKEN + DEFAULT_IM_END_TOKEN + "\n" + input_text
            else:
                input_text = DEFAULT_IMAGE_TOKEN + "\n" + input_text
            conv.append_message(conv.roles[0], input_text)
            
            # ì´ë¯¸ì§€ í…ì„œ ì²˜ë¦¬ - ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            try:
                if st.session_state.uploaded_image is not None:
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                    image_tensor = image_processor.preprocess(
                        st.session_state.uploaded_image, 
                        return_tensors="pt"
                    )["pixel_values"]
                    
                    # half precisionìœ¼ë¡œ ë³€í™˜
                    image_tensor = image_tensor.half()
                    
                    # CUDAë¡œ ì´ë™
                    image_tensor = image_tensor.cuda()
                else:
                    image_tensor = None
            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                image_tensor = None
                st.session_state.image_first_use = False
                return
            
            st.session_state.image_first_use = False
        else:
            # later messages
            conv.append_message(conv.roles[0], input_text)
            image_tensor = None
        
        conv.append_message(conv.roles[1], None)
        prompt = conv.get_prompt() + "<|im_start|>assistant\n"
        stop_str = "<|im_end|>"
        tokenizer.pad_token_id = 151662 
        input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors="pt").unsqueeze(0).cuda()
        keywords = [stop_str]
        stopping_criteria = KeywordsStoppingCriteria(keywords, tokenizer, input_ids)

        with st.chat_message("assistant"):
            # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìœ„í•œ í”Œë ˆì´ìŠ¤í™€ë”
            response_placeholder = st.empty()
            
            # ì»¤ìŠ¤í…€ ìŠ¤íŠ¸ë¦¬ë¨¸ ìƒì„±
            streamer = StreamlitStreamer(tokenizer, response_placeholder)
            
            with torch.inference_mode():
                output_ids = model.generate(
                    input_ids, 
                    images=image_tensor, 
                    do_sample=True, 
                    temperature=args["temperature"], 
                    max_new_tokens=args["max_new_tokens"],
                    streamer=streamer,
                    use_cache=True, 
                    pad_token_id=tokenizer.pad_token_id, 
                    stopping_criteria=[stopping_criteria]
                )

            # ìµœì¢… ì¶œë ¥ ìƒì„± ë° ì •ë¦¬
            outputs = tokenizer.decode(output_ids[0], skip_special_tokens=True)
            
            # í”„ë¡¬í”„íŠ¸ ë¶€ë¶„ ì œê±° (assistant ì´í›„ ë¶€ë¶„ë§Œ ì¶”ì¶œ)
            if "<|im_start|>assistant\n" in outputs:
                outputs = outputs.split("<|im_start|>assistant\n")[-1]
            
            # íŠ¹ìˆ˜ í† í° ì œê±°
            outputs = clean_output(outputs)
            
            # ìµœì¢… ê²°ê³¼ í‘œì‹œ
            response_placeholder.write(outputs)
        
        # AI ì‘ë‹µ ì €ì¥
        st.session_state.messages.append({
            "role": "assistant",
            "content": outputs
        })

        # conversationì—ë„ ì‘ë‹µ ì €ì¥
        conv.messages[-1][-1] = outputs
        


if __name__ == "__main__":
    main()
